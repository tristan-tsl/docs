# 分析

```
容器将日志发送给elk
	1、容器内嵌
	2、容器日志重定向
```



# ELK

https://github.com/deviantony/docker-elk

```
# 创建保存elk文件的文件夹
mkdir -p /data/tristan/elk  && cd /data/tristan/elk

# 下载docker stack 文件
 wget https://github.com/deviantony/docker-elk/archive/master.zip

#解压并进入该docker stack 文件位置
unzip master.zip &&	cd docker-elk-master

# 修改es的内存
vi docker-stack.yml 
# 将256 改为 2048

# 初始化docker swarm集群
docker swarm init

# 运行容器
docker stack deploy -c docker-stack.yml elk
```

几个访问地址:

| 地址                                  | 名称      | 认证            |
| ------------------------------------- | --------- | --------------- |
| http://192.168.71.223:9999/#/services | portainer | admin/portainer |
| http://192.168.71.223:5601/           | kibana    |                 |
|                                       |           |                 |

- 5000: Logstash TCP input.
- 9200: Elasticsearch HTTP
- 9300: Elasticsearch TCP transport
- 5601: Kibana

## kibna使用

kibana地址:	http://192.168.71.220:5601/app/kibana#/home?_g=()

​	在Manager界面创建zipkin*的索引

​	在Discory界面查看zipkin*索引下的日志

​	通过id进行聚合





# docker service

http://dockone.io/article/2252

在docker swarm的service 详情界面设置 Logging  Driver 为 syslog

添加参数: 	syslog-address		tcp://192.168.71.223:5000



# zipkinServer

```
docker run -d -p 9411:9411 --name zipkin --restart always \
  -e STORAGE_TYPE=elasticsearch -e ES_HOSTS=192.168.71.223:9200 \
  openzipkin/zipkin
```



http://192.168.71.220:9411





# 访问地址
