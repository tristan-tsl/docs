## 在上一个版本中(v2)

使用docker stack创建elk(elasticsearch/logstash/kibana)

配置容器的日志驱动为syslog 并且配置syslog-address地址为logstash的地址

在使用过程发现几个问题:

1、由于日志内容中没有zipkin的trace信息(spanId)导致并发调用的时候获取整个调用链日志不直观

2、 日志过于呈现形式为日志行,导致分析定位问题不直观

3、由于syslog的方式与elk耦合过重导致业务系统的启动会受到elk的影响

4、syslog会影响原来docker 日志的显示,降低docker 容器的性能



有几个好处:

配置简单，维护简单

# 设计思考

elk是否需要放到k8s容器中？

非常有必要

​	放到k8s容器之后,再通过dnsServer去固定内部访问地址可以简化配置,使得开发/测试/生产环境的配置一致

​	后期动态扩缩节点更方便(相比docker stack)

带来的坏处?

​	搭建需要时间



# 实践

## 通过k8s 部署文件 搭建elk

将kibana固定到指定标签的主机上,提供外部访问端口



## 通过service固定elk的内部访问地址



## 修改Deployment的配置指向 elk

```
      - image: sz-pg-oam-docker-hub-001.tendcloud.com/library/filebeat:5.4.0
        name: filebeat
        volumeMounts:
        - name: app-logs
          mountPath: /log
        - name: filebeat-config
          mountPath: /etc/filebeat/
```



配置使用filebeat / fluent



# 参考资料

https://www.kubernetes.org.cn/4022.html		nfs

https://www.kubernetes.org.cn/2011.html		ek + filebeat