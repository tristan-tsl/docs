---
typora-copy-images-to: 截图
---

# 建立多个环境的代码流

## 目的

为了多个环境的配置和对应代码也能管理化,自成一体

## 总体预览

对上级环境的代码流进行分支,形成自己的环境代码流代码

### 目前的代码流

```
# 目前的代码流
trunk
trunk-test-v1
trunk-product-v1
```

### 代码流的合并限制

每个流只能从上级流拉取代码并对该流设置特定用户组进行管理

```
# 代码流的合并限制
trunk-test-v1 -> trunk
trunk-product-v1 -> trunk-test-v1
```

### 项目结构

```
# 项目结构
/
	cloud-commons
	cloud-eureka
	cloud-gateway
	cloud-config
	cloud-datacenter
		trunk
			service-oa
	cloud-modules
    	service-product
    	service-erp
        service-mrp
        service-plan
		service-procurement
```

### 项目的打包顺序

项目的打包(需要修改配置)顺序:

```
# 项目的打包顺序
## 顶级配置
ebuy-cloud-parent
## 顶级依赖
cloud-commons
## 框架基础服务
cloud-eureka
cloud-config
server-oauth2
cloud-gateway
## 业务工程
cloud-modules
service-product
service-erp
service-mrp
service-plan
service-procurement
service-oa
```

###  项目的启动顺序

 项目的启动顺序:

```
# 项目的启动顺序
cloud-eureka
cloud-config
server-oauth2
cloud-gateway
service-product
service-erp
service-mrp
service-plan
service-procurement
service-oa
```

##  实际操作

### 新建分支

 ![1553433406955](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553433406955.png)

选中分支流

右键svn->Branch/tag

![1553433553710](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553433553710.png)

创建测试流分支v1版本,值为:

```
# 值
/trunk/codes/java/ebuy-cloud/branches/test-v1

# 注释
创建测试流分支v1版本
```

### 修改工程的配置

需要修改每一个需要打包的工程的配置

修改nexus的地址

修改settings.xml



# 需要搭建的服务

## 宿主机需要做的事情

### docker化

```
# 查看系统版本
 cat /etc/redhat-release
 
# 更新yum
yum update -y

# 移除掉原来安装的docker
yum -y remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
                  
# 安装依赖软件
yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2

# 配置docker的yum仓库
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
    
# 启用仓库的文件
yum-config-manager --enable docker-ce-nightly

# 安装docker-ce
yum install -y docker-ce docker-ce-cli containerd.io


# 设置镜像加速
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://q4jtpmzm.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker

# 启动docker
systemctl start docker

# 允许开机自启
systemctl enable docker

# 运行一个demo镜像
docker run hello-world
```

### 查看可用磁盘大小

```
# 查看磁盘使用情况
df -hl	
# 根据磁盘使用情况选择一个文件存放文件,通常为 例如 /data/tristan/
```



## gitlab

https://docs.gitlab.com/omnibus/docker/

```
# 创建数据挂载点
rm -rf /data/tristan/gitlab/config /data/tristan/gitlab/logs /data/tristan/gitlab/data
mkdir -p  /data/tristan/gitlab/config /data/tristan/gitlab/logs /data/tristan/gitlab/data

# 运行镜像
sudo docker run --detach \
  --hostname 192.168.71.220 \
  --publish 8929:80 --publish 2289:22 \
  --name gitlab \
  --restart always \
  --volume /data/tristan/gitlab/config:/etc/gitlab \
  --volume /data/tristan/gitlab/logs:/var/log/gitlab \
  --volume /data/tristan/gitlab/data:/var/opt/gitlab \
  gitlab/gitlab-ce:latest
  
#限制gitlab的内存
docker stop gitlab
docker update --memory-swap 4096M gitlab
docker update --memory 4096M gitlab
docker start gitlab

#查看镜像运行情况
docker logs -f gitlab

```





### 访问

http://192.168.71.220:8929	root/ebuygitlab

为root账号配置密码	root/ebuygitlab



## jenkins

```
# 创建数据挂载点
mkdir -p /data/tristan/jenkins

# 运行镜像
docker run \
  -u root \
  -d --restart always \
  -p 8080:8080 \
  -p 50000:50000 \
  -v /data/tristan/jenkins:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  --name jenkins \
  jenkinsci/blueocean
  
 # 查看镜像运行情况
 docker logs -f jenkins
```

访问地址:

http://192.168.71.220:8080	访问密码需要从docker的日志控制台拷贝出来

设置admin账号的密码	admin/admin



### 配置打包时的setting.xml

参考:

```
\\192.168.71.245\docs\tristan\ebuy-cloud部署\test-v1\settings.xml
```

#### 修改文件

修改为:

```
<?xml version="1.0" encoding="UTF-8"?>  
<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"   
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"   
          xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">  
  
  <pluginGroups></pluginGroups>  
  <proxies></proxies>  
  
  <servers>  
    <server>  	
      <id>nexus-snapshots</id>
      <username>ebuy-cloud-test</username>
      <password>ebuy-cloud-test</password>
    </server>  
  </servers>  
  
  <mirrors>   
    <mirror>   
      <id>nexus-releases</id>   
      <mirrorOf>*</mirrorOf>   
      <url>http://192.168.71.220:8081/repository/maven-public/</url>   
    </mirror>    
    <mirror>   
      <id>nexus-snapshots</id>   
      <mirrorOf>*</mirrorOf>   
      <url>http://192.168.71.220:8081/repository/maven-snapshots/</url>   
    </mirror>   
  </mirrors>   
   
  <profiles>  
	 <!-- 开发环境 (snapshots环境) -->
	<profile>
		<id>nexus-snapshots</id>
		<properties>
			<repository.id>nexus-snapshots</repository.id>
			<repository.name>nexus-snapshots</repository.name>
			<repository.url>http://192.168.71.220:8081/repository/maven-snapshots/</repository.url>
		</properties>
	</profile>
  </profiles>  
  
  <activeProfiles>  
      <activeProfile>nexus-snapshots</activeProfile>  
  </activeProfiles>  
   
</settings>  
```



#### 拷贝文件

上传该文件到/root/.m2/	文件中

```
# 在jenkins的服务器中创建maven配置目录
mkdir /root/.m2/

#移动该上传的文件到该目录中
mv ~/settings.xml /root/.m2/
```



## nexus

```
# 创建数据挂载点

# 创建本地文件夹
mkdir -p /data/tristan/nexus && chmod 777 /data/tristan/nexus

# 启动容器
docker run -d --restart always -p 8081:8081 --name nexus -v /data/tristan/nexus:/nexus-data sonatype/nexus3

# 查看镜像启动情况
docker logs -f nexus
```

访问:

​	http://192.168.71.220:8081	admin/admin123

# 使用搭建的服务

## gitalb

http://192.168.71.220:8929	root/ebuygitlab

### 创建用户

http://192.168.71.220:8929/users/sign_in

![1553442724125](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553442724125.png)





### 创建用户组

![1553442587818](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553442587818.png)

http://192.168.71.220:8929/groups/new

![1553442649567](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553442649567.png)

ebuy-cloud-test-v1

#### 为用户组添加用户

http://192.168.71.220:8929/ebuy-cloud-test-v1

![1553442800233](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553442800233.png)

http://192.168.71.220:8929/groups/ebuy-cloud-test-v1/-/group_members

![1553442858672](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553442858672.png)

### 创建项目

http://192.168.71.220:8929/projects/new

![1553445341074](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553445341074.png)

http://192.168.71.220:8929/projects/new



```
ebuy-cloud-config-test-v1
```

### 为项目设置成员组

http://192.168.71.220:8929/root/ebuy-cloud-config-test-v1/project_members

![1553445573926](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553445573926.png)

ebuy-cloud-test-v1

### 使用仓库

http://192.168.71.220:8929/root/ebuy-cloud-config-test-v1

![1553477516520](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553477516520.png)

http://192.168.71.220/root/ebuy-cloud-config-test-v1.git

实际上需要修改为:

```
http://192.168.71.220:8929/root/ebuy-cloud-config-test-v1.git
```

#### idea

在idea安装gitlab插件并重启

#### gitbash

安装git	https://git-scm.com/downloads

```
# 设置登录账号和密码
git config --global user.name "tristan"	gitlabTristan
git config --global user.email "tristan@qq.com"

# 拉取代码
git clone http://192.168.71.220:8929/root/ebuy-cloud-config-test.git
cd ebuy-cloud-config-test

# 添加到git管理
git add *	

# 提交到本地+gitlab
git commit -m "add test  test "
git push -u origin master
```



```
进入本地的文件夹
登录
拉取代码
```



## nexus

### 配置aliyun-maven代理仓库

http://192.168.71.245:8081/

![1553439049209](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439049209.png)



http://192.168.71.245:8081/#admin/repository

![1553439067920](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439067920.png)

http://192.168.71.245:8081/#admin/repository/repositories

![1553439082851](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439082851.png)

http://192.168.71.245:8081/#admin/repository/repositories

![1553439102317](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439102317.png)

http://192.168.71.245:8081/#admin/repository/repositories

![1553439166842](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439166842.png)

aliyun-maven-proxy

```
http://maven.aliyun.com/nexus/content/groups/public
```



![1553439195346](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439195346.png)

点击左下角



![1553439274088](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439274088.png)

![1553440231368](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553440231368.png)



![1553439304007](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553439304007.png)



### 创建测试环境用户

#### 创建权限角色

http://192.168.71.220:8081/#admin/security/roles

![1553500896316](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553500896316.png)

![1553500991740](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553500991740.png)

ebuy-cloud-test

snapshot



#### 创建权限用户

http://192.168.71.220:8081/#admin/security/users

![1553501030700](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553501030700.png)



![1553501080059](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553501080059.png)



## jenkins

### 创建任务

http://192.168.71.220:8080/

![1553438427133](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438427133.png)

http://192.168.71.220:8080/view/all/newJob

![1553438479486](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438479486.png)

http://192.168.71.220:8080/job/ebuy-cloud-test-v1/configure

![1553438511701](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438511701.png)



![1553438538488](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438538488.png)



![1553438577038](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438577038.png)

![1553438592352](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438592352.png)

![1553438624331](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438624331.png)

## jenkins-blue

http://192.168.71.220:8080/blue/pipelines

### 运行任务

![1553438695921](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438695921.png)

http://192.168.71.220:8080/blue/organizations/jenkins/ebuy-cloud-test-v1/activity

![1553438714929](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553438714929.png)







# 一些可能用到的指令

```
# 清理服务器内存
echo 2 > /proc/sys/vm/drop_caches

```

# 实际操作

## 源码中

### ebuy-cloud-parent

```
# 名称
test-v1-parent

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1

# jenkisnfile地址
jenkins/Jenkinsfile
```

加入jenkinsfile

参考:

```
\\192.168.71.245\docs\tristan\ebuy-cloud部署\test-v1
```

具体:

```
pipeline {
    agent {
        docker {
            image 'maven:3-alpine'
            args '-v /root/.m2:/root/.m2'
        }
    }
    stages {
        stage('Deliver') {
            steps {
                sh 'mvn deploy'
            }
        }
    }
}

```



将jenkins文件夹拷贝入到该项目的下一级地址即可

```
# jenkisnfile地址
jenkins/Jenkinsfile
```

#修改pom.xml，加入

```
<!--打包到私有库上&从私有库上拉取依赖-->
<distributionManagement>
    <repository>
        <id>${repository.id}</id>
        <name>${repository.name}</name>
        <url>${repository.url}</url>
        <layout>default</layout>
    </repository>
</distributionManagement>
```

### cloud-commons

```
# 名称
test-v1-cloud-commons

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-commons

# jenkisnfile地址
jenkins/Jenkinsfile
```

拷入jenkins文件夹

### cloud-eureka

#### 修改配置文件名称

修改src\main\resources下的application.properties/yml 或者 bootstrap.properties/yml文件

修改为该 原文件名称-test.原后缀 (idea 快捷键为 Shift+F6)

![1553440395995](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553440395995.png)

#### 修改其中的内容

![1553441329656](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553441329656.png)

修改为另一台eureka 服务器所在的地址

```
# 名称
test-v1-cloud-eureka

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-eureka

# jenkisnfile地址
jenkins/Jenkinsfile
```

#### 下载jar文件

http://192.168.71.220:8081/#browse/search/maven=attributes.maven2.artifactId%3Dcloud-eureka

在nexus的maven仓库中搜索cloud-eureka

在snapshot树上搜索cloud-eureka

http://192.168.71.220:8081/#browse/browse:maven-snapshots:com

在Path一栏右击该链接 进行复制链接,在服务器上进行下载并运行(需要加上后缀运行),例如

```
# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/eureka/cloud-eureka/0.0.1-SNAPSHOT/cloud-eureka-0.0.1-20190328.114920-16.jar -O cloud-eureka.jar

# 运行220节点的指令
nohup java -jar cloud-eureka.jar --spring.profiles.active=test220 -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > cloud-eureka220.log 2>&1 &

# 运行221节点的指令
nohup java -jar cloud-eureka.jar --spring.profiles.active=test221  > cloud-eureka221.log 2>&1 &


# 查看该日志
tail -f cloud-eureka220.log
tail -f cloud-eureka221.log
```

访问

http://192.168.71.221:9000/	root/123456

### cloud-config

在gitlab上创建配置文件项目

```
http://192.168.71.220:8929/root/ebuy-cloud-config-test-v1.git
```

修改配置文件

![1553478788639](Z:\tristan\ebuy-cloud部署\test-v1\截图\1553478788639.png)



以test的profile启动

测试访问: http://localhost:9201/service-product-test.properties



```
# 名称
test-v1-cloud-config

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-config

# jenkisnfile地址
jenkins/Jenkinsfile
```



```
# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/config/cloud-config/0.0.1-SNAPSHOT/cloud-config-0.0.1-20190328.120410-9.jar -O cloud-config.jar

# 运行的指令
nohup java -jar cloud-config.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > cloud-config.log 2>&1 &

# 查看该日志
tail -f cloud-config.log
```



访问

http://192.168.71.221:9201/service-product-test.properties

### server-oauth2

```
# 名称
test-v1-server-oauth2

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/server-oauth2

# jenkisnfile地址
jenkins/Jenkinsfile
```



```
# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/server/oauth2/server-oauth2/0.0.1-SNAPSHOT/server-oauth2-0.0.1-20190328.142315-6.jar -O server-oauth2.jar

# 运行的指令
nohup java -jar server-oauth2.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > server-oauth2.log 2>&1 &

# 查看该日志
tail -f server-oauth2.log
```

http://192.168.71.221:9092

### cloud-gateway

```
# 名称
test-v1-cloud-gateway

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-gateway

# jenkisnfile地址
jenkins/Jenkinsfile
```



```
# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/gateway/cloud-gateway/0.0.1-SNAPSHOT/cloud-gateway-0.0.1-20190328.144452-10.jar -O cloud-gateway.jar

# 运行的指令
nohup java -jar cloud-gateway.jar --spring.profiles.active=test  > cloud-gateway.log 2>&1 &


# 查看该日志
tail -f cloud-gateway.log
```

http://192.168.71.221:5000



### cloud-modules

```
# 名称
test-v1-cloud-modules

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules

# jenkisnfile地址
jenkins/Jenkinsfile
```

### service-product

```
# 名称
test-v1-service-product

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-product

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/product/service-product/0.0.1-SNAPSHOT/service-product-0.0.1-20190329.024620-10.jar -O service-product.jar

# 运行的指令
nohup java -jar service-product.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > service-product.log 2>&1 &

# 查看该日志
tail -f service-product.log
```



http://192.168.71.221:9090

### service-erp



```
# 名称
test-v1-service-erp

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-erp

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/service/erp/service-erp/0.0.1-SNAPSHOT/service-erp-0.0.1-20190328.124248-6.jar -O service-erp.jar

# 运行的指令
nohup java -jar service-erp.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > service-erp.log 2>&1 &


# 查看该日志
tail -f service-erp.log
```

http://192.168.71.221:9999

### service-mrp



```
# 名称
test-v1-service-mrp

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-mrp

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/service/mrp/service-mrp/0.0.1-SNAPSHOT/service-mrp-0.0.1-20190329.130446-16.jar -O service-mrp.jar

# 运行的指令
nohup java -jar service-mrp.jar --spring.profiles.active=test  > service-mrp.log 2>&1 &

# 查看该日志
tail -f service-mrp.log
```

http://192.168.71.221:9099

### service-plan



```
# 名称
test-v1-service-plan

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-plan

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/service/plan/service-plan/0.0.1-SNAPSHOT/service-plan-0.0.1-20190328.134539-5.jar -O service-plan.jar

# 运行的指令
nohup java -jar service-plan.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > service-plan.log 2>&1 &

# 查看该日志
tail -f service-plan.log
```

http://192.168.71.221:9096

### service-procurement



```
# 名称
test-v1-service-procurement

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-procurement

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/procurement/service-procurement/0.0.1-SNAPSHOT/service-procurement-0.0.1-20190328.140239-10.jar -O service-procurement.jar

# 运行的指令
nohup java -jar service-procurement.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > service-procurement.log 2>&1 &

# 查看该日志
tail -f service-procurement.log
```

http://192.168.71.221:9091



### service-logistics

```
# 名称
test-v1-service-logistics

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-modules/service-logistics

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/logistics/service-logistics/0.0.1-SNAPSHOT/service-logistics-0.0.1-20190329.021900-7.jar -O service-logistics.jar

# 运行的指令
nohup java -jar service-logistics.jar --spring.profiles.active=test -Xms128m -Xmx512m -XX:PermSize=64M -XX:MaxPermSize=128M > service-logistics.log 2>&1 &

# 查看该日志
tail -f service-logistics.log
```



### cloud-datacenter

```
# 名称
test-v1-cloud-datacenter

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-datacenter/trunk

# jenkisnfile地址
jenkins/Jenkinsfile
```



### service-oa

```
# 名称
test-v1-service-oa

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-datacenter/trunk/service-oa

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/service/oa/service-oa/0.0.1-SNAPSHOT/service-oa-0.0.1-20190328.141234-7.jar -O service-oa.jar

# 运行的指令
nohup java -jar service-oa.jar --spring.profiles.active=test  > service-oa.log 2>&1 &

# 查看该日志
tail -f service-oa.log
```

### cloud-basics

```
# 名称
test-v1-cloud-basics

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-basics

# jenkisnfile地址
jenkins/Jenkinsfile
```



### service-file

```
# 名称
test-v1-service-file

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-basics/service-file

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/file/service-file/0.0.1-SNAPSHOT/service-file-0.0.1-20190331.094403-6.jar -O service-file.jar

# 运行的指令
nohup java -jar service-file.jar --spring.profiles.active=test  > service-file.log 2>&1 &

# 查看该日志
tail -f service-file.log
```

### service-alibaba-order

```
# 名称
test-v1-service-alibaba-order

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-basics/service-alibaba-order

# jenkisnfile地址
jenkins/Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/basic/alibaba/order/service-alibaba-order/0.0.1-SNAPSHOT/service-alibaba-order-0.0.1-20190329.131535-5.jar -O service-alibaba-order.jar

# 运行的指令
nohup java -jar service-alibaba-order.jar --spring.profiles.active=test  > service-alibaba-order.log 2>&1 &

# 查看该日志
tail -f service-alibaba-order.log
```



### service-util

```
# 名称
test-v1-service-util

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/branches/test-v1/cloud-basics/service-util

# jenkisnfile地址
Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/util/service-util/0.0.1-SNAPSHOT/service-util-0.0.1-20190331.102951-2.jar -O service-util.jar

# 运行的指令
nohup java -jar service-util.jar --spring.profiles.active=test  > service-util.log 2>&1 &

# 查看该日志
tail -f service-util.log
```

### service-elasticsearch

```
# 名称
test-v1-service-elasticsearch

# svn地址
http://192.168.71.205:8088/svn/yibai_cloud/trunk/codes/java/ebuy-cloud/trunk/cloud-datacenter/trunk/service-elasticsearch

# jenkisnfile地址
Jenkinsfile

# 进入服务器的部署目录
cd /data/tristan/java

# 复制的地址例如:
wget http://192.168.71.220:8081/repository/maven-snapshots/com/ebuy/cloud/service/elasticsearch/service-elasticsearch/0.0.1-SNAPSHOT/service-elasticsearch-0.0.1-20190331.104623-2.jar -O service-elasticsearch.jar

# 运行的指令
nohup java -jar service-elasticsearch.jar --spring.profiles.active=test  > service-elasticsearch.log 2>&1 &

# 查看该日志
tail -f service-elasticsearch.log

```



# jar 管理

http://192.168.71.220:8081/#browse/browse:maven-snapshots

```
# 启动
java -jar xxx.jar --spring.profiles.active=test

# 停止
ps axu|grep java
kill -9 上面的pid
rm -rf xxx.jar

```

# 访问地址

http://192.168.71.221:9000/

http://192.168.71.221:9201/service-plan-test.properties

http://192.168.71.221:5000/

http://192.168.71.221:9403/

http://192.168.71.221:9090/templates/login.html

http://192.168.71.221:9999/templates/login.html

http://192.168.71.221:9099/templates/login.html

http://192.168.71.221:9091/templates/login.html







http://192.168.71.220:8080/

http://192.168.71.220:8080/blue/pipelines

http://192.168.71.220:8081/#browse/browse:maven-snapshots:com

http://192.168.71.220:8929

https://gitee.com/yibai_repos/ebuy_cloud



# 一些问题

服务的密码管理的问题

​	nexus

​	jenkins

​	gitlab

​	svn

服务的账号的权限限制的问题

​	nexus-snapshot

​	jenkins-test

​	gitlab-test

​	svn-test

工程中的配置文件尚未完全改造的问题

​	工程中有部分配置文件没有改成成读取配置文件

spring cloud 本身的认证的问题

​	eureka server

​	spring cloud config

重复端口的问题

工程打包插件的问题

​	需要全部使用spring boot 远程打包插件

工程切换nexus的问题

​	需要在顶层pom中配置指向本地的settings.xml文件

settings.xml的问题

​	需要为不同的数据源配置不同的账号并配置到server节点,同时需要修改activeProfile节点的值

eureka双节点的问题

​	eureka提供多套profile配置

​	需要每个服务配置eureka双节点服务器

# 一些其他的服务

## fastdfs

storage.conf

```
# is this config file disabled
# false for enabled
# true for disabled
disabled=false

# the name of the group this storage server belongs to
#
# comment or remove this item for fetching from tracker server,
# in this case, use_storage_id must set to true in tracker.conf,
# and storage_ids.conf must be configed correctly.
group_name=group1

# bind an address of this host
# empty for bind all addresses of this host
bind_addr=

# if bind an address of this host when connect to other servers 
# (this storage server as a client)
# true for binding the address configed by above parameter: "bind_addr"
# false for binding any address of this host
client_bind=true

# the storage server port
port=23000

# connect timeout in seconds
# default value is 30s
connect_timeout=10

# network timeout in seconds
# default value is 30s
network_timeout=60

# heart beat interval in seconds
heart_beat_interval=30

# disk usage report interval in seconds
stat_report_interval=60

# the base path to store data and log files
base_path=/var/local/fdfs/storage

# max concurrent connections the server supported
# default value is 256
# more max_connections means more memory will be used
# you should set this parameter larger, eg. 10240
max_connections=1024

# the buff size to recv / send data
# this parameter must more than 8KB
# default value is 64KB
# since V2.00
buff_size = 256KB

# accept thread count
# default value is 1
# since V4.07
accept_threads=1

# work thread count, should <= max_connections
# work thread deal network io
# default value is 4
# since V2.00
work_threads=4

# if disk read / write separated
##  false for mixed read and write
##  true for separated read and write
# default value is true
# since V2.00
disk_rw_separated = true

# disk reader thread count per store base path
# for mixed read / write, this parameter can be 0
# default value is 1
# since V2.00
disk_reader_threads = 1

# disk writer thread count per store base path
# for mixed read / write, this parameter can be 0
# default value is 1
# since V2.00
disk_writer_threads = 1

# when no entry to sync, try read binlog again after X milliseconds
# must > 0, default value is 200ms
sync_wait_msec=50

# after sync a file, usleep milliseconds
# 0 for sync successively (never call usleep)
sync_interval=0

# storage sync start time of a day, time format: Hour:Minute
# Hour from 0 to 23, Minute from 0 to 59
sync_start_time=00:00

# storage sync end time of a day, time format: Hour:Minute
# Hour from 0 to 23, Minute from 0 to 59
sync_end_time=23:59

# write to the mark file after sync N files
# default value is 500
write_mark_file_freq=500

# path(disk or mount point) count, default value is 1
store_path_count=9

# store_path#, based 0, if store_path0 not exists, it's value is base_path
# the paths must be exist
#store_path0=/var/local/fdfs/storage
#store_path1=/var/local/fdfs/storage2
store_path0=/data/product/upload/image/main
store_path1=/data/product/upload/image/assistant
store_path2=/data/product/upload/image/image
store_path3=/data/product/upload/image/tmp
store_path4=/data/product/upload/image/thumb
store_path5=/data/product/upload/image/thumbnails
store_path6=/data/product/upload/image/thumb_no_log
store_path7=/data/product/upload/image/product_images
store_path8=/data/purchase/upload/image


# subdir_count  * subdir_count directories will be auto created under each 
# store_path (disk), value can be 1 to 256, default value is 256
subdir_count_per_path=256

# tracker_server can ocur more than once, and tracker_server format is
#  "host:port", host can be hostname or ip address
tracker_server=192.168.71.220:22122

#standard log level as syslog, case insensitive, value list:
### emerg for emergency
### alert
### crit for critical
### error
### warn for warning
### notice
### info
### debug
log_level=info

#unix group name to run this program, 
#not set (empty) means run by the group of current user
run_by_group=

#unix username to run this program,
#not set (empty) means run by current user
run_by_user=

# allow_hosts can ocur more than once, host can be hostname or ip address,
# "*" (only one asterisk) means match all ip addresses
# we can use CIDR ips like 192.168.5.64/26
# and also use range like these: 10.0.1.[0-254] and host[01-08,20-25].domain.com
# for example:
# allow_hosts=10.0.1.[1-15,20]
# allow_hosts=host[01-08,20-25].domain.com
# allow_hosts=192.168.5.64/26
allow_hosts=*

# the mode of the files distributed to the data path
# 0: round robin(default)
# 1: random, distributted by hash code
file_distribute_path_mode=0

# valid when file_distribute_to_path is set to 0 (round robin), 
# when the written file count reaches this number, then rotate to next path
# default value is 100
file_distribute_rotate_count=100

# call fsync to disk when write big file
# 0: never call fsync
# other: call fsync when written bytes >= this bytes
# default value is 0 (never call fsync)
fsync_after_written_bytes=0

# sync log buff to disk every interval seconds
# must > 0, default value is 10 seconds
sync_log_buff_interval=10

# sync binlog buff / cache to disk every interval seconds
# default value is 60 seconds
sync_binlog_buff_interval=10

# sync storage stat info to disk every interval seconds
# default value is 300 seconds
sync_stat_file_interval=300

# thread stack size, should >= 512KB
# default value is 512KB
thread_stack_size=512KB

# the priority as a source server for uploading file.
# the lower this value, the higher its uploading priority.
# default value is 10
upload_priority=10

# the NIC alias prefix, such as eth in Linux, you can see it by ifconfig -a
# multi aliases split by comma. empty value means auto set by OS type
# default values is empty
if_alias_prefix=

# if check file duplicate, when set to true, use FastDHT to store file indexes
# 1 or yes: need check
# 0 or no: do not check
# default value is 0
check_file_duplicate=0

# file signature method for check file duplicate
## hash: four 32 bits hash code
## md5: MD5 signature
# default value is hash
# since V4.01
file_signature_method=hash

# namespace for storing file indexes (key-value pairs)
# this item must be set when check_file_duplicate is true / on
key_namespace=FastDFS

# set keep_alive to 1 to enable persistent connection with FastDHT servers
# default value is 0 (short connection)
keep_alive=0

# you can use "#include filename" (not include double quotes) directive to 
# load FastDHT server list, when the filename is a relative path such as 
# pure filename, the base path is the base path of current/this config file.
# must set FastDHT server list when check_file_duplicate is true / on
# please see INSTALL of FastDHT for detail
##include /home/yuqing/fastdht/conf/fdht_servers.conf

# if log to access log
# default value is false
# since V4.00
use_access_log = false

# if rotate the access log every day
# default value is false
# since V4.00
rotate_access_log = false

# rotate access log time base, time format: Hour:Minute
# Hour from 0 to 23, Minute from 0 to 59
# default value is 00:00
# since V4.00
access_log_rotate_time=00:00

# if rotate the error log every day
# default value is false
# since V4.02
rotate_error_log = false

# rotate error log time base, time format: Hour:Minute
# Hour from 0 to 23, Minute from 0 to 59
# default value is 00:00
# since V4.02
error_log_rotate_time=00:00

# rotate access log when the log file exceeds this size
# 0 means never rotates log file by log file size
# default value is 0
# since V4.02
rotate_access_log_size = 0

# rotate error log when the log file exceeds this size
# 0 means never rotates log file by log file size
# default value is 0
# since V4.02
rotate_error_log_size = 0

# keep days of the log files
# 0 means do not delete old log files
# default value is 0
log_file_keep_days = 0

# if skip the invalid record when sync file
# default value is false
# since V4.02
file_sync_skip_invalid_record=false

# if use connection pool
# default value is false
# since V4.05
use_connection_pool = false

# connections whose the idle time exceeds this time will be closed
# unit: second
# default value is 3600
# since V4.05
connection_pool_max_idle_time = 3600

# use the ip address of this storage server if domain_name is empty,
# else this domain name will ocur in the url redirected by the tracker server
http.domain_name=

# the port of the web server on this storage server
http.server_port=80
```

nginx.conf

```
           events {
           worker_connections  1024;
           }
           http {
           include       mime.types;
           default_type  application/octet-stream;
           server {
               listen 80;
               server_name localhost;
               location ~ /group[0-9]/M00 {
                 ngx_fastdfs_module;
               }
             }
            }
```



```
# 创建挂载数据文件夹
rm -rf /data/tristan/fastdfs/*
mkdir -p /data/tristan/fastdfs /data/tristan/fastdfs-conf


# 覆盖自定义配置文件
## 容器内
/etc/fdfs/storage.conf
/usr/local/nginx/conf/nginx.conf

## 挂载本机并覆盖
-v /data/tristan/fastdfs-conf/storage.conf:/etc/fdfs/storage.conf
-v /data/tristan/fastdfs-conf/nginx.conf:/usr/local/nginx/conf/nginx.conf



# 运行镜像
docker run -d --restart=always --privileged=true --net=host --name=fastdfs -e IP=192.168.71.221 -e WEB_PORT=80 -v /data/tristan/fastdfs-conf/storage.conf:/etc/fdfs/storage.conf -v /data/tristan/fastdfs-conf/nginx.conf:/usr/local/nginx/conf/nginx.conf -v /data/tristan/fastdfs:/var/local/fdfs qbanxiaoli/fastdfs

docker run -d --restart=always --privileged=true --net=host --name=fastdfs -e IP=192.168.71.221 -e WEB_PORT=80 -v /data/tristan/fastdfs:/var/local/fdfs qbanxiaoli/fastdfs
```

验证是否可用:

```
docker exec -it fastdfs bash
mkdir -p /data/tristan/fastdfs/ && cd /data/tristan/fastdfs/
echo "Hello FastDFS!">index.html
fdfs_test /etc/fdfs/client.conf upload index.html
```

## test